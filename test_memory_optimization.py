#!/usr/bin/env python3
"""
æµ‹è¯•å†…å­˜ä¼˜åŒ–æ•ˆæœçš„è„šæœ¬
"""

import psutil
import time
import os
from pathlib import Path

def get_memory_usage():
    """è·å–å½“å‰è¿›ç¨‹å†…å­˜ä½¿ç”¨é‡(MB)"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / (1024 * 1024)

def test_old_method(file_path):
    """æµ‹è¯•æ—§æ–¹æ³•ï¼šä¸€æ¬¡æ€§è¯»å–æ•´ä¸ªæ–‡ä»¶"""
    print("ğŸ§ª æµ‹è¯•æ—§æ–¹æ³•ï¼ˆä¸€æ¬¡æ€§è¯»å–ï¼‰...")
    start_memory = get_memory_usage()
    start_time = time.time()
    
    try:
        import pandas as pd
        df = pd.read_parquet(file_path)
        peak_memory = get_memory_usage()
        elapsed = time.time() - start_time
        
        print(f"  âœ… æˆåŠŸè¯»å– {len(df):,} è¡Œ")
        print(f"  ğŸ“Š å†…å­˜ä½¿ç”¨: {start_memory:.1f} â†’ {peak_memory:.1f} MB (å¢åŠ  {peak_memory - start_memory:.1f} MB)")
        print(f"  â±ï¸  è€—æ—¶: {elapsed:.2f} ç§’")
        
        return peak_memory - start_memory
        
    except Exception as e:
        print(f"  âŒ å¤±è´¥: {e}")
        return None

def test_new_method(file_path):
    """æµ‹è¯•æ–°æ–¹æ³•ï¼šæµå¼è¯»å–"""
    print("ğŸš€ æµ‹è¯•æ–°æ–¹æ³•ï¼ˆæµå¼è¯»å–ï¼‰...")
    start_memory = get_memory_usage()
    start_time = time.time()
    
    try:
        import pyarrow.parquet as pq
        
        parquet_file = pq.ParquetFile(file_path)
        total_rows = parquet_file.metadata.num_rows
        
        # æ¨¡æ‹Ÿå¤„ç†é…ç½®
        cache_size = 1000  # å°ç¼“å­˜æµ‹è¯•
        processed_rows = 0
        max_memory = start_memory
        
        for batch in parquet_file.iter_batches(batch_size=cache_size):
            df_chunk = batch.to_pandas()
            processed_rows += len(df_chunk)
            
            current_memory = get_memory_usage()
            max_memory = max(max_memory, current_memory)
            
            # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            time.sleep(0.01)
        
        elapsed = time.time() - start_time
        
        print(f"  âœ… æˆåŠŸå¤„ç† {processed_rows:,} è¡Œ (æ€»è®¡ {total_rows:,})")
        print(f"  ğŸ“Š å†…å­˜ä½¿ç”¨: {start_memory:.1f} â†’ {max_memory:.1f} MB (å³°å€¼å¢åŠ  {max_memory - start_memory:.1f} MB)")
        print(f"  â±ï¸  è€—æ—¶: {elapsed:.2f} ç§’")
        
        return max_memory - start_memory
        
    except Exception as e:
        print(f"  âŒ å¤±è´¥: {e}")
        return None

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” å†…å­˜ä¼˜åŒ–æ•ˆæœæµ‹è¯•")
    print("=" * 50)
    
    # æŸ¥æ‰¾æµ‹è¯•æ–‡ä»¶
    data_dir = Path("/mnt/project/yifan/data/the-stack-v2-dedup_batched_download")
    if not data_dir.exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return
    
    parquet_files = list(data_dir.glob("*.parquet"))
    if not parquet_files:
        print("âŒ æœªæ‰¾åˆ°parquetæ–‡ä»¶")
        return
    
    # é€‰æ‹©ä¸€ä¸ªè¾ƒå¤§çš„æ–‡ä»¶è¿›è¡Œæµ‹è¯•
    test_file = max(parquet_files, key=lambda f: f.stat().st_size)
    file_size_mb = test_file.stat().st_size / (1024 * 1024)
    
    print(f"ğŸ¯ æµ‹è¯•æ–‡ä»¶: {test_file.name}")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB")
    print()
    
    # æµ‹è¯•æ–°æ–¹æ³•ï¼ˆå®‰å…¨ï¼‰
    new_memory = test_new_method(test_file)
    print()
    
    # åªæœ‰åœ¨æ–‡ä»¶ä¸å¤ªå¤§æ—¶æ‰æµ‹è¯•æ—§æ–¹æ³•
    if file_size_mb < 500:  # é™åˆ¶åœ¨500MBä»¥ä¸‹
        old_memory = test_old_method(test_file)
        print()
        
        if old_memory and new_memory:
            improvement = ((old_memory - new_memory) / old_memory) * 100
            print(f"ğŸ‰ å†…å­˜ä¼˜åŒ–æ•ˆæœ: å‡å°‘ {improvement:.1f}% å†…å­˜ä½¿ç”¨")
    else:
        print("âš ï¸  æ–‡ä»¶è¿‡å¤§ï¼Œè·³è¿‡æ—§æ–¹æ³•æµ‹è¯•ï¼ˆé¿å…å†…å­˜çˆ†ç‚¸ï¼‰")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    main()
