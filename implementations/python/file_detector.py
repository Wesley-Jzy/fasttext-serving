#!/usr/bin/env python3
"""
å¢é‡æ–‡ä»¶æ£€æµ‹å™¨ - åˆ¤æ–­parquetæ–‡ä»¶æ˜¯å¦å†™å…¥å®Œæˆ
"""
import os
import time
import pandas as pd
from pathlib import Path
from typing import List, Tuple, Optional
import logging

class IncrementalFileDetector:
    """å¢é‡æ–‡ä»¶æ£€æµ‹å™¨"""
    
    def __init__(self, stability_window: int = 30):
        """
        Args:
            stability_window: æ–‡ä»¶ç¨³å®šæ€§çª—å£(ç§’)ï¼Œæ–‡ä»¶åœ¨æ­¤æ—¶é—´å†…æ— å˜åŒ–æ‰è®¤ä¸ºå®Œæ•´
        """
        self.stability_window = stability_window
        self.file_states = {}  # æ–‡ä»¶çŠ¶æ€ç¼“å­˜
        
    def is_file_ready(self, file_path: Path) -> Tuple[bool, str]:
        """
        æ£€æµ‹æ–‡ä»¶æ˜¯å¦å†™å…¥å®Œæˆå¹¶å¯å¤„ç†
        
        Returns:
            (is_ready, reason)
        """
        if not file_path.exists():
            return False, "file_not_exists"
            
        try:
            # 1. æ£€æŸ¥æ–‡ä»¶å¤§å°ç¨³å®šæ€§
            current_size = file_path.stat().st_size
            current_mtime = file_path.stat().st_mtime
            
            # ç©ºæ–‡ä»¶ç›´æ¥è·³è¿‡
            if current_size == 0:
                return False, "empty_file"
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨ç¨³å®šçª—å£å†…æœ‰å˜åŒ–
            if str(file_path) in self.file_states:
                last_size, last_mtime, last_check = self.file_states[str(file_path)]
                
                # æ–‡ä»¶å‘ç”Ÿäº†å˜åŒ–ï¼Œé‡æ–°è®¡æ—¶
                if current_size != last_size or current_mtime != last_mtime:
                    self.file_states[str(file_path)] = (current_size, current_mtime, time.time())
                    return False, "file_still_changing"
                
                # æ–‡ä»¶åœ¨ç¨³å®šçª—å£å†…æ— å˜åŒ–
                if time.time() - last_check >= self.stability_window:
                    # å°è¯•è¯»å–éªŒè¯
                    return self._validate_parquet_readable(file_path)
                else:
                    return False, f"waiting_stability_{int(self.stability_window - (time.time() - last_check))}s"
            else:
                # é¦–æ¬¡æ£€æµ‹ï¼Œè®°å½•çŠ¶æ€
                self.file_states[str(file_path)] = (current_size, current_mtime, time.time())
                return False, "first_detection"
                
        except Exception as e:
            return False, f"check_error_{str(e)}"
    
    def _validate_parquet_readable(self, file_path: Path) -> Tuple[bool, str]:
        """éªŒè¯parquetæ–‡ä»¶æ˜¯å¦å¯è¯»"""
        try:
            # å°è¯•è¯»å–æ–‡ä»¶å¤´ä¿¡æ¯ï¼ˆä¸åŠ è½½å…¨éƒ¨æ•°æ®ï¼‰
            df_info = pd.read_parquet(file_path, engine='pyarrow')
            
            # åŸºæœ¬å®Œæ•´æ€§æ£€æŸ¥
            if len(df_info) == 0:
                return False, "empty_dataframe"
                
            # æ£€æŸ¥å¿…éœ€åˆ—
            required_columns = ['content']  # æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´
            missing_cols = [col for col in required_columns if col not in df_info.columns]
            if missing_cols:
                return False, f"missing_columns_{missing_cols}"
                
            return True, "ready"
            
        except Exception as e:
            return False, f"parquet_error_{str(e)}"
    
    def scan_ready_files(self, data_dir: Path, pattern: str = "*.parquet") -> List[Path]:
        """æ‰«æç›®å½•ä¸­å·²å‡†å¤‡å¥½çš„æ–‡ä»¶"""
        ready_files = []
        
        for file_path in data_dir.glob(pattern):
            is_ready, reason = self.is_file_ready(file_path)
            
            if is_ready:
                ready_files.append(file_path)
                logging.info(f"âœ… Ready: {file_path.name}")
            else:
                logging.debug(f"â³ Waiting: {file_path.name} ({reason})")
        
        return ready_files
    
    def cleanup_states(self, data_dir: Path):
        """æ¸…ç†ä¸å­˜åœ¨æ–‡ä»¶çš„çŠ¶æ€ç¼“å­˜"""
        existing_files = {str(f) for f in data_dir.glob("*.parquet")}
        
        # ç§»é™¤ä¸å­˜åœ¨æ–‡ä»¶çš„çŠ¶æ€
        self.file_states = {
            path: state for path, state in self.file_states.items() 
            if path in existing_files
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æ£€æµ‹parquetæ–‡ä»¶å®Œæ•´æ€§')
    parser.add_argument('--data-dir', required=True, help='æ•°æ®ç›®å½•')
    parser.add_argument('--stability-window', type=int, default=30, help='ç¨³å®šæ€§çª—å£(ç§’)')
    parser.add_argument('--watch', action='store_true', help='æŒç»­ç›‘æ§æ¨¡å¼')
    
    args = parser.parse_args()
    
    logging.basicConfig(level=logging.INFO)
    detector = IncrementalFileDetector(args.stability_window)
    data_dir = Path(args.data_dir)
    
    if args.watch:
        print(f"ğŸ” æŒç»­ç›‘æ§: {data_dir}")
        while True:
            ready_files = detector.scan_ready_files(data_dir)
            print(f"ğŸ“Š å‡†å¤‡å°±ç»ª: {len(ready_files)} ä¸ªæ–‡ä»¶")
            
            detector.cleanup_states(data_dir)
            time.sleep(10)
    else:
        ready_files = detector.scan_ready_files(data_dir)
        print(f"ğŸ“‹ å¯å¤„ç†æ–‡ä»¶:")
        for f in ready_files:
            print(f"  {f}")
