#!/usr/bin/env python3
"""
ç®€åŒ–æ ‡ç­¾éªŒè¯è„šæœ¬ï¼šåªå¯¹æ¯”é¢„æµ‹æ ‡ç­¾ä¸çœŸå®æ ‡ç­¾æ˜¯å¦ä¸€è‡´
"""

import pandas as pd
import asyncio
import aiohttp
import time
from typing import List, Dict, Any

class LabelValidator:
    def __init__(self, service_url: str = "http://localhost:8000"):
        self.service_url = service_url
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def predict_batch(self, texts: List[str], batch_size: int = 50) -> List[Dict[str, Any]]:
        """æ‰¹é‡é¢„æµ‹æ–‡æœ¬"""
        if not texts:
            return []
        
        # é™åˆ¶æ‰¹æ¬¡å¤§å°é¿å…è¶…æ—¶
        batch_texts = texts[:batch_size]
        
        try:
            async with self.session.post(
                f"{self.service_url}/predict",
                json=batch_texts,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return result
                else:
                    print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status}")
                    return [None for _ in batch_texts]
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¼‚å¸¸: {e}")
            return [None for _ in batch_texts]
    
    def parse_prediction(self, pred_result) -> tuple:
        """è§£æé¢„æµ‹ç»“æœï¼Œè¿”å›(æ ‡ç­¾, å¾—åˆ†)"""
        if not pred_result:
            return ("__label__0", 0.0)  # é»˜è®¤æ ‡ç­¾å’Œå¾—åˆ†
            
        try:
            # æ­£ç¡®çš„APIæ ¼å¼ï¼š{"labels": [...], "scores": [...]}
            if isinstance(pred_result, dict):
                labels = pred_result.get("labels", [])
                scores = pred_result.get("scores", [])
                
                if labels and scores:
                    # å–å¾—åˆ†æœ€é«˜çš„ï¼ˆç¬¬ä¸€ä¸ªå°±æ˜¯æœ€é«˜åˆ†ï¼‰
                    raw_label = labels[0]
                    score = scores[0]
                    
                    # ç¡®ä¿æ ‡ç­¾æ ¼å¼æ­£ç¡®
                    if raw_label.startswith('__label__'):
                        return (raw_label, score)
                    else:
                        return (f"__label__{raw_label}", score)
                        
        except Exception as e:
            print(f"âŒ è§£æé¢„æµ‹ç»“æœå¤±è´¥: {e}")
        
        return ("__label__0", 0.0)  # é»˜è®¤æ ‡ç­¾å’Œå¾—åˆ†
    
    async def validate_all_labels(self, val_file: str, max_samples: int = None):
        """éªŒè¯æ‰€æœ‰æ ·æœ¬çš„æ ‡ç­¾åˆ†ç±»æ­£ç¡®æ€§"""
        print(f"ğŸ“– è¯»å–éªŒè¯é›†: {val_file}")
        
        try:
            df = pd.read_parquet(val_file)
        except Exception as e:
            print(f"âŒ è¯»å–éªŒè¯é›†å¤±è´¥: {e}")
            return
        
        print(f"ğŸ“Š éªŒè¯é›†ä¿¡æ¯:")
        print(f"  æ€»æ ·æœ¬æ•°: {len(df):,}")
        print(f"  æ ‡ç­¾åˆ†å¸ƒ: {df['FT_label'].value_counts().to_dict()}")
        
        # é™åˆ¶æ ·æœ¬æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        if max_samples:
            df = df.head(max_samples)
            print(f"ğŸ”¬ æµ‹è¯•æ¨¡å¼: åªéªŒè¯å‰ {len(df)} ä¸ªæ ·æœ¬")
        
        # è·å–å†…å®¹å’ŒçœŸå®æ ‡ç­¾
        contents = df['clean_content'].tolist()
        true_labels = df['FT_label'].tolist()
        
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡é¢„æµ‹ {len(contents)} ä¸ªæ ·æœ¬...")
        start_time = time.time()
        
        # è®°å½•æ‰€æœ‰æ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯
        all_samples = []
        
        # åˆ†æ‰¹é¢„æµ‹
        batch_size = 50
        
        for i in range(0, len(contents), batch_size):
            batch_contents = contents[i:i+batch_size]
            batch_predictions = await self.predict_batch(batch_contents, batch_size)
            
            # è®°å½•æ¯ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯
            for j, (content, true_label, pred_result) in enumerate(zip(batch_contents, true_labels[i:i+batch_size], batch_predictions)):
                pred_label, pred_score = self.parse_prediction(pred_result)
                
                sample_info = {
                    'index': i + j,
                    'content': content,
                    'true_label': true_label,
                    'pred_label': pred_label,
                    'pred_score': pred_score,
                    'matched': true_label == pred_label
                }
                all_samples.append(sample_info)
            
            if (i // batch_size + 1) % 20 == 0:
                print(f"  å·²å¤„ç†: {i + len(batch_contents)}/{len(contents)} æ ·æœ¬")
        
        total_time = time.time() - start_time
        print(f"âœ… é¢„æµ‹å®Œæˆï¼Œè€—æ—¶: {total_time:.2f}ç§’")
        print(f"ğŸ“Š ååé‡: {len(contents) / total_time:.1f} samples/sec")
        
        # ç»Ÿä¸€åˆ†ææ‰€æœ‰æ ·æœ¬æ•°æ®
        self.analyze_results(all_samples, total_time)
        
        # è¿”å›ç»“æœ
        correct_count = sum(1 for sample in all_samples if sample['matched'])
        return {
            'total_samples': len(all_samples),
            'correct_predictions': correct_count,
            'accuracy': correct_count / len(all_samples),
            'processing_time': total_time,
            'throughput': len(all_samples) / total_time
        }
    

    

    


    def analyze_results(self, all_samples: List[Dict], total_time: float):
        """ç»Ÿä¸€åˆ†ææ‰€æœ‰æ ·æœ¬çš„ç»“æœ"""
        from collections import Counter
        
        # æå–æ ‡ç­¾ä¿¡æ¯
        true_labels = [sample['true_label'] for sample in all_samples]
        pred_labels = [sample['pred_label'] for sample in all_samples]
        
        # 1. FT_labelç»Ÿè®¡ä¿¡æ¯ï¼ˆçœŸå®æ ‡ç­¾åˆ†å¸ƒï¼‰
        true_counts = Counter(true_labels)
        print(f"\nğŸ“Š FT_labelç»Ÿè®¡ä¿¡æ¯ï¼ˆéªŒè¯é›†çœŸå®æ ‡ç­¾ï¼‰:")
        for label, count in sorted(true_counts.items()):
            pct = count / len(true_labels) * 100
            print(f"  {label}: {count:,} ({pct:.1f}%)")
        
        # 2. æˆ‘ä»¬çš„é¢„æµ‹ç»Ÿè®¡ä¿¡æ¯
        pred_counts = Counter(pred_labels)
        print(f"\nğŸ“Š æˆ‘ä»¬çš„é¢„æµ‹ç»Ÿè®¡ä¿¡æ¯:")
        for label, count in sorted(pred_counts.items()):
            pct = count / len(pred_labels) * 100
            print(f"  {label}: {count:,} ({pct:.1f}%)")
        
        # 3. åŒ¹é…ç‡
        correct_count = sum(1 for sample in all_samples if sample['matched'])
        accuracy = correct_count / len(all_samples)
        print(f"\nğŸ¯ éªŒè¯ç»“æœ:")
        print(f"æ€»æ ·æœ¬æ•°: {len(all_samples):,}")
        print(f"åŒ¹é…æ ·æœ¬æ•°: {correct_count:,}")
        print(f"ä¸åŒ¹é…æ ·æœ¬æ•°: {len(all_samples) - correct_count:,}")
        print(f"åŒ¹é…ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        
        # 4. ä¸åŒ¹é…æ ·æœ¬è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…å«åˆ†æ•°ï¼‰
        mismatched_samples = [sample for sample in all_samples if not sample['matched']]
        
        if mismatched_samples:
            print(f"\nâŒ ä¸åŒ¹é…æ ·æœ¬è¯¦æƒ…ï¼ˆå‰15ä¸ªï¼‰:")
            print(f"{'æ ·æœ¬':<6} {'çœŸå®æ ‡ç­¾':<15} {'é¢„æµ‹æ ‡ç­¾':<15} {'é¢„æµ‹åˆ†æ•°':<10} {'å†…å®¹é¢„è§ˆ':<30}")
            print("-" * 80)
            
            for sample in mismatched_samples[:15]:
                content_preview = sample['content'][:30].replace('\n', ' ') + "..." if len(sample['content']) > 30 else sample['content'].replace('\n', ' ')
                print(f"{sample['index']+1:<6} {sample['true_label']:<15} {sample['pred_label']:<15} {sample['pred_score']:<10.4f} {content_preview:<30}")
            
            if len(mismatched_samples) > 15:
                print(f"\n... è¿˜æœ‰ {len(mismatched_samples) - 15} ä¸ªä¸åŒ¹é…æ ·æœ¬")
            
            # åˆ†æä¸åŒ¹é…çš„ç±»å‹åˆ†å¸ƒ
            mismatch_types = Counter([(sample['true_label'], sample['pred_label']) for sample in mismatched_samples])
            print(f"\nğŸ“ˆ ä¸åŒ¹é…ç±»å‹åˆ†å¸ƒ:")
            for (true_label, pred_label), count in mismatch_types.most_common():
                pct = count / len(mismatched_samples) * 100
                print(f"  {true_label} â†’ {pred_label}: {count} ä¸ªæ ·æœ¬ ({pct:.1f}%)")
        else:
            print(f"\nğŸ‰ æ‰€æœ‰æ ‡ç­¾éƒ½åŒ¹é…ï¼")

async def main():
    import argparse
    parser = argparse.ArgumentParser(description='FastTextæ ‡ç­¾éªŒè¯è„šæœ¬')
    parser.add_argument('--service-url', 
                        default='http://localhost:8000',
                        help='FastTextæœåŠ¡URL')
    parser.add_argument('--val-file',
                        default='/mnt/project/yifan/data/code/the-stack-v2_fasttext_val_with_gt.parquet',
                        help='éªŒè¯é›†æ–‡ä»¶')
    parser.add_argument('--max-samples', 
                        type=int,
                        help='æœ€å¤§éªŒè¯æ ·æœ¬æ•°ï¼ˆä¸æŒ‡å®šåˆ™éªŒè¯å…¨éƒ¨ï¼‰')
    
    args = parser.parse_args()
    
    async with LabelValidator(args.service_url) as validator:
        await validator.validate_all_labels(args.val_file, args.max_samples)

if __name__ == "__main__":
    asyncio.run(main())
