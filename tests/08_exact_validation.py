#!/usr/bin/env python3
"""
ç²¾ç¡®éªŒè¯è„šæœ¬ï¼šé€ä¸ªå¯¹æ¯”æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ
éªŒè¯æˆ‘ä»¬çš„æ¨ç†æ¡†æ¶ä¸ç®—æ³•è®­ç»ƒæ—¶çš„ç»“æœæ˜¯å¦å®Œå…¨ä¸€è‡´
"""

import pandas as pd
import numpy as np
import asyncio
import aiohttp
import json
from typing import List, Dict, Any

class ExactValidator:
    def __init__(self, service_url: str = "http://localhost:8000"):
        self.service_url = service_url
        self.session = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def predict_single(self, text: str) -> Dict[str, Any]:
        """å•ä¸ªæ–‡æœ¬é¢„æµ‹"""
        try:
            async with self.session.post(
                f"{self.service_url}/predict",
                json=[text],
                timeout=aiohttp.ClientTimeout(total=10)
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return result[0] if result else None
                else:
                    print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status}")
                    return None
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¼‚å¸¸: {e}")
            return None
    
    def parse_prediction(self, pred_result) -> tuple:
        """è§£æé¢„æµ‹ç»“æœï¼Œè¿”å›(æ ‡ç­¾, åˆ†æ•°)"""
        if not pred_result:
            return None, None
            
        try:
            if isinstance(pred_result, list) and len(pred_result) >= 2:
                labels = pred_result[0]
                scores = pred_result[1]
                
                if labels and scores:
                    # å–å¾—åˆ†æœ€é«˜çš„
                    max_idx = np.argmax(scores)
                    raw_label = labels[max_idx]
                    score = scores[max_idx]
                    
                    # è½¬æ¢æ ‡ç­¾æ ¼å¼
                    if raw_label.startswith('__label__'):
                        label = raw_label
                    else:
                        label = f"__label__{raw_label}"
                    
                    return label, score
        except Exception as e:
            print(f"âŒ è§£æé¢„æµ‹ç»“æœå¤±è´¥: {e}")
        
        return None, None
    
    async def validate_samples(self, val_file: str, max_samples: int = 10):
        """é€ä¸ªéªŒè¯æ ·æœ¬"""
        print(f"ğŸ“– è¯»å–éªŒè¯é›†: {val_file}")
        
        try:
            df = pd.read_parquet(val_file)
        except Exception as e:
            print(f"âŒ è¯»å–éªŒè¯é›†å¤±è´¥: {e}")
            return
        
        print(f"ğŸ“Š éªŒè¯é›†ä¿¡æ¯:")
        print(f"  æ€»æ ·æœ¬æ•°: {len(df):,}")
        print(f"  åŒ…å«åˆ†æ•°åˆ—: {[col for col in df.columns if 'score' in col.lower()]}")
        
        # é™åˆ¶æ ·æœ¬æ•°
        if max_samples:
            df = df.head(max_samples)
            print(f"ğŸ”¬ éªŒè¯å‰ {len(df)} ä¸ªæ ·æœ¬")
        
        print(f"\nğŸš€ å¼€å§‹é€ä¸ªéªŒè¯...")
        print("=" * 100)
        
        exact_matches = 0
        label_matches = 0
        total_samples = 0
        score_diffs = []
        
        for idx, row in df.iterrows():
            total_samples += 1
            content = row['content']
            true_label = row['FT_label']
            
            # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®åˆ†æ•°
            true_score = None
            if 'score' in row:
                true_score = row['score']
            elif 'score_fancreation' in row:
                true_score = row['score_fancreation']
            
            print(f"\næ ·æœ¬ {total_samples}/{len(df)}:")
            print(f"  å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            print(f"  çœŸå®æ ‡ç­¾: {true_label}")
            if true_score is not None:
                print(f"  çœŸå®åˆ†æ•°: {true_score:.6f}")
            
            # è·å–æˆ‘ä»¬çš„é¢„æµ‹
            pred_result = await self.predict_single(content)
            pred_label, pred_score = self.parse_prediction(pred_result)
            
            if pred_label is None:
                print(f"  âŒ é¢„æµ‹å¤±è´¥")
                continue
            
            print(f"  æˆ‘ä»¬æ ‡ç­¾: {pred_label}")
            print(f"  æˆ‘ä»¬åˆ†æ•°: {pred_score:.6f}")
            
            # æ ‡ç­¾å¯¹æ¯”
            label_match = (pred_label == true_label)
            if label_match:
                label_matches += 1
                print(f"  âœ… æ ‡ç­¾åŒ¹é…")
            else:
                print(f"  âŒ æ ‡ç­¾ä¸åŒ¹é…: {pred_label} != {true_label}")
            
            # åˆ†æ•°å¯¹æ¯”
            score_match = False
            if true_score is not None:
                score_diff = abs(pred_score - true_score)
                score_diffs.append(score_diff)
                score_match = score_diff < 0.001  # å…è®¸0.1%çš„è¯¯å·®
                
                print(f"  åˆ†æ•°å·®å¼‚: {score_diff:.6f}")
                if score_match:
                    print(f"  âœ… åˆ†æ•°åŒ¹é…")
                else:
                    print(f"  âŒ åˆ†æ•°å·®å¼‚è¿‡å¤§")
            
            # å®Œå…¨åŒ¹é…
            if label_match and (true_score is None or score_match):
                exact_matches += 1
                print(f"  ğŸ¯ å®Œå…¨åŒ¹é…")
            
            print("-" * 50)
        
        # æ€»ç»“
        print(f"\nğŸ“Š éªŒè¯æ€»ç»“:")
        print("=" * 50)
        print(f"éªŒè¯æ ·æœ¬æ•°: {total_samples}")
        print(f"æ ‡ç­¾åŒ¹é…: {label_matches}/{total_samples} ({label_matches/total_samples*100:.1f}%)")
        print(f"å®Œå…¨åŒ¹é…: {exact_matches}/{total_samples} ({exact_matches/total_samples*100:.1f}%)")
        
        if score_diffs:
            print(f"\nåˆ†æ•°å·®å¼‚ç»Ÿè®¡:")
            print(f"  å¹³å‡å·®å¼‚: {np.mean(score_diffs):.6f}")
            print(f"  æœ€å¤§å·®å¼‚: {np.max(score_diffs):.6f}")
            print(f"  åˆ†æ•°åŒ¹é…: {sum(1 for d in score_diffs if d < 0.001)}/{len(score_diffs)}")
        
        # åˆ¤æ–­æ¡†æ¶æ˜¯å¦æ­£ç¡®
        if label_matches / total_samples > 0.95:
            print(f"\nâœ… æ¡†æ¶éªŒè¯é€šè¿‡ï¼æ ‡ç­¾åŒ¹é…ç‡ > 95%")
        else:
            print(f"\nâŒ æ¡†æ¶éªŒè¯å¤±è´¥ï¼æ ‡ç­¾åŒ¹é…ç‡åªæœ‰ {label_matches/total_samples*100:.1f}%")
            print(f"   å¯èƒ½åŸå› ï¼šæ ‡ç­¾æ˜ å°„é”™è¯¯ã€æ¨¡å‹æ–‡ä»¶ä¸åŒã€é¢„å¤„ç†å·®å¼‚")

async def main():
    import argparse
    parser = argparse.ArgumentParser(description='ç²¾ç¡®éªŒè¯FastTextæ¨ç†æ¡†æ¶')
    parser.add_argument('--service-url', 
                        default='http://localhost:8000',
                        help='FastTextæœåŠ¡URL')
    parser.add_argument('--val-file',
                        default='/mnt/project/yifan/data/code/the-stack-v2_fasttext_val_with_gt.parquet',
                        help='éªŒè¯é›†æ–‡ä»¶')
    parser.add_argument('--max-samples', 
                        type=int, 
                        default=10,
                        help='æœ€å¤§éªŒè¯æ ·æœ¬æ•°')
    
    args = parser.parse_args()
    
    async with ExactValidator(args.service_url) as validator:
        await validator.validate_samples(args.val_file, args.max_samples)

if __name__ == "__main__":
    asyncio.run(main())
