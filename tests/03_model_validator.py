#!/usr/bin/env python3
"""
æ¨¡å‹éªŒè¯è„šæœ¬
æµ‹è¯•FastTextæ¨¡å‹åŠ è½½ã€äºŒåˆ†ç±»åŠŸèƒ½ã€æ€§èƒ½è¡¨ç°
"""
import os
import sys
import time
import json
from typing import List, Tuple, Dict, Any

def test_fasttext_import():
    """æµ‹è¯•FastTextåº“å¯¼å…¥"""
    print("ğŸ“¦ æµ‹è¯•FastTextåº“")
    
    try:
        import fasttext
        print(f"âœ… FastTextå¯¼å…¥æˆåŠŸ")
        if hasattr(fasttext, '__version__'):
            print(f"  ç‰ˆæœ¬: {fasttext.__version__}")
        return True
    except ImportError as e:
        print(f"âŒ FastTextå¯¼å…¥å¤±è´¥: {e}")
        return False

def load_model(model_path: str):
    """åŠ è½½FastTextæ¨¡å‹"""
    print(f"ğŸ¤– åŠ è½½æ¨¡å‹: {model_path}")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
        return None
    
    try:
        import fasttext
        start_time = time.time()
        model = fasttext.load_model(model_path)
        load_time = time.time() - start_time
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ ({load_time:.2f}ç§’)")
        return model
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

def analyze_model_info(model):
    """åˆ†ææ¨¡å‹åŸºæœ¬ä¿¡æ¯"""
    print("ğŸ” æ¨¡å‹ä¿¡æ¯åˆ†æ")
    
    if model is None:
        return {}
    
    try:
        # è·å–æ ‡ç­¾
        labels = model.get_labels()
        print(f"ğŸ“‹ æ¨¡å‹æ ‡ç­¾: {labels}")
        print(f"  æ ‡ç­¾æ•°é‡: {len(labels)}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯äºŒåˆ†ç±»
        is_binary = len(labels) == 2
        has_label_format = all(label.startswith('__label__') for label in labels)
        
        print(f"ğŸ¯ äºŒåˆ†ç±»æ£€æŸ¥:")
        print(f"  æ˜¯å¦äºŒåˆ†ç±»: {is_binary}")
        print(f"  æ ‡ç­¾æ ¼å¼æ­£ç¡®: {has_label_format}")
        
        if is_binary and has_label_format:
            label0 = labels[0].replace('__label__', '')
            label1 = labels[1].replace('__label__', '')
            print(f"  ç±»åˆ«0: {label0}")
            print(f"  ç±»åˆ«1: {label1}")
        
        # è·å–è¯æ±‡è¡¨å¤§å°
        try:
            words = model.get_words()
            print(f"ğŸ“š è¯æ±‡è¡¨å¤§å°: {len(words)}")
        except:
            print(f"âš ï¸ æ— æ³•è·å–è¯æ±‡è¡¨ä¿¡æ¯")
        
        model_info = {
            "labels": labels,
            "is_binary": is_binary,
            "has_correct_format": has_label_format,
            "vocab_size": len(words) if 'words' in locals() else None
        }
        
        return model_info
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¿¡æ¯åˆ†æå¤±è´¥: {e}")
        return {}

def test_prediction_basic(model) -> Dict[str, Any]:
    """æµ‹è¯•åŸºæœ¬é¢„æµ‹åŠŸèƒ½"""
    print("\nğŸ§ª åŸºæœ¬é¢„æµ‹æµ‹è¯•")
    
    if model is None:
        return {}
    
    # æµ‹è¯•æ ·æœ¬ï¼ˆä»£ç ç‰‡æ®µï¼‰
    test_samples = [
        "def hello_world():\n    print('Hello, World!')\n",
        "import numpy as np\narray = np.zeros((10, 10))\nprint(array.shape)\n",
        "function calculateSum(a, b) {\n    return a + b;\n}\nconsole.log(calculateSum(5, 3));\n",
        "# This is a comment\n# TODO: implement feature\npass\n",
        "SELECT * FROM users WHERE age > 18 ORDER BY name;\n"
    ]
    
    results = []
    
    for i, text in enumerate(test_samples):
        print(f"\n--- æ ·æœ¬ {i+1} ---")
        print(f"è¾“å…¥: {repr(text[:50])}...")
        
        try:
            # ä½¿ç”¨predictæ–¹æ³•ï¼ˆè·å–æœ€å¯èƒ½çš„æ ‡ç­¾ï¼‰
            labels, probs = model.predict(text, k=2)  # è·å–top-2ç»“æœ
            
            print(f"é¢„æµ‹ç»“æœ:")
            for label, prob in zip(labels, probs):
                clean_label = label.replace('__label__', '')
                print(f"  {clean_label}: {prob:.4f}")
            
            results.append({
                "input": text[:100],
                "labels": [l.replace('__label__', '') for l in labels],
                "probabilities": [float(p) for p in probs]
            })
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            results.append({
                "input": text[:100],
                "error": str(e)
            })
    
    return {"test_results": results}

def test_prediction_performance(model, sample_count: int = 100) -> Dict[str, Any]:
    """æµ‹è¯•é¢„æµ‹æ€§èƒ½"""
    print(f"\nâš¡ æ€§èƒ½æµ‹è¯• (æ ·æœ¬æ•°: {sample_count})")
    
    if model is None:
        return {}
    
    # ç”Ÿæˆæµ‹è¯•æ ·æœ¬
    base_samples = [
        "def function():\n    return True\n",
        "import os\nprint(os.getcwd())\n",
        "class MyClass:\n    def __init__(self):\n        pass\n",
        "try:\n    result = process()\nexcept Exception as e:\n    print(e)\n"
    ]
    
    # æ‰©å±•åˆ°æŒ‡å®šæ•°é‡
    test_samples = []
    for i in range(sample_count):
        base = base_samples[i % len(base_samples)]
        # æ·»åŠ ä¸€äº›å˜åŒ–ä½¿æ ·æœ¬ä¸å®Œå…¨ç›¸åŒ
        sample = f"# Sample {i}\n{base}"
        test_samples.append(sample)
    
    print(f"ç”Ÿæˆ {len(test_samples)} ä¸ªæµ‹è¯•æ ·æœ¬")
    
    # å•æ¬¡é¢„æµ‹æ€§èƒ½æµ‹è¯•
    print("ğŸ“Š å•æ¬¡é¢„æµ‹æµ‹è¯•...")
    single_times = []
    
    for i in range(min(10, sample_count)):
        start_time = time.time()
        try:
            labels, probs = model.predict(test_samples[i], k=2)
            elapsed = time.time() - start_time
            single_times.append(elapsed)
        except Exception as e:
            print(f"âš ï¸ å•æ¬¡é¢„æµ‹å¤±è´¥: {e}")
    
    if single_times:
        avg_single_time = sum(single_times) / len(single_times)
        print(f"  å¹³å‡å•æ¬¡é¢„æµ‹æ—¶é—´: {avg_single_time*1000:.2f}ms")
        print(f"  é¢„ä¼°å•æ¬¡å¤„ç†é€Ÿåº¦: {1/avg_single_time:.0f} samples/sec")
    
    # æ‰¹é‡é¢„æµ‹æ€§èƒ½æµ‹è¯•
    print("ğŸ“Š æ‰¹é‡é¢„æµ‹æµ‹è¯•...")
    batch_sizes = [1, 10, 100] if sample_count >= 100 else [1, min(10, sample_count)]
    
    performance_results = {
        "single_prediction_ms": avg_single_time * 1000 if single_times else None,
        "batch_results": []
    }
    
    for batch_size in batch_sizes:
        if batch_size > len(test_samples):
            continue
            
        batch_samples = test_samples[:batch_size]
        
        start_time = time.time()
        success_count = 0
        
        for sample in batch_samples:
            try:
                labels, probs = model.predict(sample, k=2)
                success_count += 1
            except Exception as e:
                print(f"âš ï¸ æ‰¹é‡é¢„æµ‹ä¸­å‡ºé”™: {e}")
        
        elapsed = time.time() - start_time
        
        if elapsed > 0:
            throughput = success_count / elapsed
            print(f"  æ‰¹é‡å¤§å° {batch_size}: {throughput:.0f} samples/sec")
            
            performance_results["batch_results"].append({
                "batch_size": batch_size,
                "throughput_per_sec": throughput,
                "success_rate": success_count / batch_size
            })
    
    return performance_results

def test_long_text_handling(model) -> Dict[str, Any]:
    """æµ‹è¯•é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›"""
    print(f"\nğŸ“ é•¿æ–‡æœ¬å¤„ç†æµ‹è¯•")
    
    if model is None:
        return {}
    
    # åˆ›å»ºä¸åŒé•¿åº¦çš„æµ‹è¯•æ–‡æœ¬
    base_code = """
def complex_function(data):
    '''
    This is a complex function that processes data
    and returns meaningful results.
    '''
    import numpy as np
    import pandas as pd
    
    # Data preprocessing
    cleaned_data = []
    for item in data:
        if item is not None:
            processed = str(item).strip().lower()
            if len(processed) > 0:
                cleaned_data.append(processed)
    
    # Statistical analysis
    if len(cleaned_data) > 0:
        result = {
            'count': len(cleaned_data),
            'unique': len(set(cleaned_data)),
            'avg_length': sum(len(x) for x in cleaned_data) / len(cleaned_data)
        }
        return result
    else:
        return {'error': 'No valid data found'}

# Usage example
sample_data = ['hello', 'world', None, '', 'python', 'fasttext']
result = complex_function(sample_data)
print(result)
"""
    
    length_tests = []
    
    # æµ‹è¯•ä¸åŒé•¿åº¦
    for multiplier in [1, 5, 10, 50, 100]:
        long_text = base_code * multiplier
        length = len(long_text)
        
        print(f"æµ‹è¯•é•¿åº¦: {length:,} å­—ç¬¦ (x{multiplier})")
        
        try:
            start_time = time.time()
            labels, probs = model.predict(long_text, k=2)
            elapsed = time.time() - start_time
            
            print(f"  âœ… æˆåŠŸ - è€—æ—¶: {elapsed:.3f}s")
            print(f"  é¢„æµ‹: {labels[0].replace('__label__', '')} ({probs[0]:.3f})")
            
            length_tests.append({
                "length": length,
                "multiplier": multiplier,
                "success": True,
                "time_seconds": elapsed,
                "prediction": labels[0].replace('__label__', ''),
                "confidence": float(probs[0])
            })
            
        except Exception as e:
            print(f"  âŒ å¤±è´¥: {e}")
            length_tests.append({
                "length": length,
                "multiplier": multiplier,
                "success": False,
                "error": str(e)
            })
    
    return {"length_tests": length_tests}

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– FastTextæ¨¡å‹éªŒè¯")
    print("=" * 50)
    
    model_path = "/mnt/project/yifan/ckpts/FT_the-stack-v2/FT_the-stack-v2.bin"
    
    # 1. æµ‹è¯•FastTextå¯¼å…¥
    if not test_fasttext_import():
        print("âŒ FastTextåº“æœ‰é—®é¢˜ï¼Œåœæ­¢æµ‹è¯•")
        return
    
    # 2. åŠ è½½æ¨¡å‹
    model = load_model(model_path)
    if model is None:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œåœæ­¢æµ‹è¯•")
        return
    
    # 3. åˆ†ææ¨¡å‹ä¿¡æ¯
    model_info = analyze_model_info(model)
    
    # 4. åŸºæœ¬é¢„æµ‹æµ‹è¯•
    basic_results = test_prediction_basic(model)
    
    # 5. æ€§èƒ½æµ‹è¯•
    performance_results = test_prediction_performance(model, sample_count=50)
    
    # 6. é•¿æ–‡æœ¬æµ‹è¯•
    long_text_results = test_long_text_handling(model)
    
    # æ±‡æ€»ç»“æœ
    validation_results = {
        "model_info": model_info,
        "basic_prediction": basic_results,
        "performance": performance_results,
        "long_text_handling": long_text_results
    }
    
    # ä¿å­˜ç»“æœ
    output_file = "model_validation_result.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(validation_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… æ¨¡å‹éªŒè¯å®Œæˆ!")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥:")
    print(f"  1. æ£€æŸ¥éªŒè¯ç»“æœæ–‡ä»¶")
    print(f"  2. æ‰§è¡ŒæœåŠ¡æµ‹è¯•: python3 tests/04_service_test.py")

if __name__ == "__main__":
    main()
