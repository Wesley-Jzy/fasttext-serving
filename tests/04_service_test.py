#!/usr/bin/env python3
"""
æœåŠ¡è¿é€šæ€§æµ‹è¯•è„šæœ¬
æµ‹è¯•FastText ServingæœåŠ¡çš„è¿æ¥ã€APIè°ƒç”¨ã€æ€§èƒ½è¡¨ç°
"""
import asyncio
import aiohttp
import requests
import json
import time
from typing import List, Dict, Any, Optional

def test_service_health(base_url: str) -> Dict[str, Any]:
    """æµ‹è¯•æœåŠ¡å¥åº·çŠ¶æ€"""
    print(f"ğŸ¥ æµ‹è¯•æœåŠ¡å¥åº·çŠ¶æ€: {base_url}")
    
    health_url = f"{base_url}/health"
    
    try:
        response = requests.get(health_url, timeout=10)
        
        if response.status_code == 200:
            health_data = response.json()
            print(f"âœ… æœåŠ¡å¥åº·æ­£å¸¸")
            print(f"  å“åº”: {health_data}")
            return {"status": "healthy", "response": health_data}
        else:
            print(f"âš ï¸ æœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            return {"status": "unhealthy", "status_code": response.status_code}
            
    except Exception as e:
        print(f"âŒ æœåŠ¡è¿æ¥å¤±è´¥: {e}")
        return {"status": "error", "error": str(e)}

def test_basic_prediction(base_url: str) -> Dict[str, Any]:
    """æµ‹è¯•åŸºæœ¬é¢„æµ‹åŠŸèƒ½"""
    print(f"\nğŸ§ª æµ‹è¯•åŸºæœ¬é¢„æµ‹åŠŸèƒ½")
    
    predict_url = f"{base_url}/predict"
    
    # æµ‹è¯•æ ·æœ¬
    test_samples = [
        "def hello():\n    print('Hello World')\n",
        "import numpy as np\narray = np.array([1, 2, 3])\n",
        "SELECT * FROM users;\n"
    ]
    
    results = []
    
    for i, text in enumerate(test_samples):
        print(f"\n--- æµ‹è¯•æ ·æœ¬ {i+1} ---")
        print(f"è¾“å…¥: {repr(text[:30])}...")
        
        try:
            payload = [text]  # å‘é€å•ä¸ªæ ·æœ¬çš„æ•°ç»„
            params = {"k": 2, "threshold": 0.0}
            
            response = requests.post(
                predict_url, 
                json=payload, 
                params=params,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                print(f"âœ… é¢„æµ‹æˆåŠŸ")
                print(f"  å“åº”æ ¼å¼: {type(result)}")
                
                if isinstance(result, list) and len(result) > 0:
                    prediction = result[0]  # ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç»“æœ
                    if isinstance(prediction, list) and len(prediction) == 2:
                        labels, scores = prediction
                        print(f"  æ ‡ç­¾: {labels}")
                        print(f"  åˆ†æ•°: {scores}")
                        
                        results.append({
                            "input": text[:50],
                            "success": True,
                            "labels": labels,
                            "scores": scores
                        })
                    else:
                        print(f"  æ„å¤–çš„å“åº”æ ¼å¼: {prediction}")
                        results.append({
                            "input": text[:50],
                            "success": False,
                            "error": f"Unexpected format: {prediction}"
                        })
                else:
                    print(f"  ç©ºå“åº”æˆ–æ ¼å¼é”™è¯¯: {result}")
                    results.append({
                        "input": text[:50],
                        "success": False,
                        "error": f"Empty or invalid response"
                    })
            else:
                error_text = response.text
                print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
                print(f"  é”™è¯¯: {error_text}")
                results.append({
                    "input": text[:50],
                    "success": False,
                    "status_code": response.status_code,
                    "error": error_text
                })
                
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
            results.append({
                "input": text[:50],
                "success": False,
                "error": str(e)
            })
    
    return {"basic_prediction_results": results}

async def test_async_performance(base_url: str, concurrent_requests: int = 5, samples_per_request: int = 10) -> Dict[str, Any]:
    """æµ‹è¯•å¼‚æ­¥å¹¶å‘æ€§èƒ½"""
    print(f"\nâš¡ å¼‚æ­¥å¹¶å‘æ€§èƒ½æµ‹è¯•")
    print(f"  å¹¶å‘è¯·æ±‚æ•°: {concurrent_requests}")
    print(f"  æ¯è¯·æ±‚æ ·æœ¬æ•°: {samples_per_request}")
    
    # ç”Ÿæˆæµ‹è¯•æ ·æœ¬
    base_samples = [
        "def func():\n    return 42\n",
        "import sys\nprint(sys.version)\n",
        "class Test:\n    pass\n",
        "try:\n    x = 1/0\nexcept:\n    pass\n"
    ]
    
    # ä¸ºæ¯ä¸ªè¯·æ±‚å‡†å¤‡æ ·æœ¬
    all_requests = []
    for req_id in range(concurrent_requests):
        request_samples = []
        for i in range(samples_per_request):
            base = base_samples[i % len(base_samples)]
            sample = f"# Request {req_id} Sample {i}\n{base}"
            request_samples.append(sample)
        all_requests.append(request_samples)
    
    async def send_request(session: aiohttp.ClientSession, request_id: int, samples: List[str]) -> Dict[str, Any]:
        """å‘é€å•ä¸ªå¼‚æ­¥è¯·æ±‚"""
        url = f"{base_url}/predict"
        params = {"k": 2, "threshold": 0.0}
        
        try:
            start_time = time.time()
            async with session.post(url, json=samples, params=params) as response:
                elapsed = time.time() - start_time
                
                if response.status == 200:
                    result = await response.json()
                    return {
                        "request_id": request_id,
                        "success": True,
                        "samples_count": len(samples),
                        "response_time": elapsed,
                        "throughput": len(samples) / elapsed if elapsed > 0 else 0
                    }
                else:
                    error_text = await response.text()
                    return {
                        "request_id": request_id,
                        "success": False,
                        "error": f"HTTP {response.status}: {error_text}",
                        "response_time": elapsed
                    }
        except Exception as e:
            return {
                "request_id": request_id,
                "success": False,
                "error": str(e),
                "response_time": time.time() - start_time if 'start_time' in locals() else 0
            }
    
    # æ‰§è¡Œå¹¶å‘è¯·æ±‚
    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as session:
        start_time = time.time()
        
        tasks = [
            send_request(session, i, samples) 
            for i, samples in enumerate(all_requests)
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        total_elapsed = time.time() - start_time
    
    # åˆ†æç»“æœ
    successful_results = [r for r in results if isinstance(r, dict) and r.get("success", False)]
    failed_results = [r for r in results if not (isinstance(r, dict) and r.get("success", False))]
    
    total_samples = sum(r.get("samples_count", 0) for r in successful_results)
    total_throughput = total_samples / total_elapsed if total_elapsed > 0 else 0
    
    print(f"ğŸ“Š å¹¶å‘æµ‹è¯•ç»“æœ:")
    print(f"  æˆåŠŸè¯·æ±‚: {len(successful_results)}/{len(results)}")
    print(f"  æ€»å¤„ç†æ ·æœ¬: {total_samples}")
    print(f"  æ€»è€—æ—¶: {total_elapsed:.2f}ç§’")
    print(f"  æ€»ååé‡: {total_throughput:.0f} samples/sec")
    
    if successful_results:
        avg_response_time = sum(r["response_time"] for r in successful_results) / len(successful_results)
        print(f"  å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}ç§’")
    
    return {
        "concurrent_requests": concurrent_requests,
        "samples_per_request": samples_per_request,
        "total_samples": total_samples,
        "total_time": total_elapsed,
        "total_throughput": total_throughput,
        "successful_requests": len(successful_results),
        "failed_requests": len(failed_results),
        "success_rate": len(successful_results) / len(results) if results else 0
    }

def test_large_batch(base_url: str, batch_sizes: List[int] = [10, 50, 100, 500]) -> Dict[str, Any]:
    """æµ‹è¯•å¤§æ‰¹é‡å¤„ç†"""
    print(f"\nğŸ“¦ å¤§æ‰¹é‡å¤„ç†æµ‹è¯•")
    
    batch_results = []
    
    # å‡†å¤‡åŸºç¡€æ ·æœ¬
    base_code = "def sample_function():\n    return 'test'\n"
    
    for batch_size in batch_sizes:
        print(f"\n--- æ‰¹é‡å¤§å°: {batch_size} ---")
        
        # ç”Ÿæˆæ‰¹é‡æ ·æœ¬
        samples = []
        for i in range(batch_size):
            sample = f"# Sample {i}\n{base_code}"
            samples.append(sample)
        
        try:
            url = f"{base_url}/predict"
            params = {"k": 2, "threshold": 0.0}
            
            start_time = time.time()
            response = requests.post(
                url, 
                json=samples, 
                params=params,
                timeout=120  # å¢åŠ è¶…æ—¶æ—¶é—´
            )
            elapsed = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                throughput = batch_size / elapsed if elapsed > 0 else 0
                
                print(f"  âœ… æˆåŠŸå¤„ç† {batch_size} æ ·æœ¬")
                print(f"  è€—æ—¶: {elapsed:.2f}ç§’")
                print(f"  ååé‡: {throughput:.0f} samples/sec")
                
                batch_results.append({
                    "batch_size": batch_size,
                    "success": True,
                    "response_time": elapsed,
                    "throughput": throughput
                })
            else:
                print(f"  âŒ å¤±è´¥: HTTP {response.status_code}")
                batch_results.append({
                    "batch_size": batch_size,
                    "success": False,
                    "status_code": response.status_code,
                    "error": response.text[:200]
                })
                
        except Exception as e:
            print(f"  âŒ å¼‚å¸¸: {e}")
            batch_results.append({
                "batch_size": batch_size,
                "success": False,
                "error": str(e)
            })
    
    return {"batch_test_results": batch_results}

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ FastText Serving æœåŠ¡æµ‹è¯•")
    print("=" * 50)
    
    # è¿™é‡Œéœ€è¦ç”¨æˆ·æä¾›å®é™…çš„æœåŠ¡URL
    # base_url = "http://localhost:8000"  # é»˜è®¤æœ¬åœ°
    base_url = "http://fasttext-serving-4nodes.serving.va-mlp.anuttacon.com"  # ç”¨æˆ·æä¾›çš„URL
    
    print(f"ğŸ¯ æµ‹è¯•ç›®æ ‡: {base_url}")
    
    # 1. å¥åº·æ£€æŸ¥
    health_result = test_service_health(base_url)
    
    if health_result.get("status") != "healthy":
        print("âŒ æœåŠ¡ä¸å¥åº·ï¼Œåœæ­¢æµ‹è¯•")
        return
    
    # 2. åŸºæœ¬é¢„æµ‹æµ‹è¯•
    basic_result = test_basic_prediction(base_url)
    
    # 3. å¼‚æ­¥å¹¶å‘æµ‹è¯•
    async_result = await test_async_performance(base_url, concurrent_requests=3, samples_per_request=5)
    
    # 4. å¤§æ‰¹é‡æµ‹è¯•
    batch_result = test_large_batch(base_url, batch_sizes=[10, 50, 100])
    
    # æ±‡æ€»ç»“æœ
    test_results = {
        "service_url": base_url,
        "health_check": health_result,
        "basic_prediction": basic_result,
        "async_performance": async_result,
        "batch_processing": batch_result
    }
    
    # ä¿å­˜ç»“æœ
    output_file = "service_test_result.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(test_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… æœåŠ¡æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"\nğŸ“‹ ä¸‹ä¸€æ­¥:")
    print(f"  1. æ£€æŸ¥æœåŠ¡æµ‹è¯•ç»“æœ")
    print(f"  2. å¼€å‘ç”Ÿäº§å®¢æˆ·ç«¯: python3 tests/05_production_client.py")

if __name__ == "__main__":
    asyncio.run(main())
