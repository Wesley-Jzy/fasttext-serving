#!/usr/bin/env python3
"""
The-Stack-v2 å¤§è§„æ¨¡ä»£ç è´¨é‡åˆ†ç±»å®¢æˆ·ç«¯
"""

import asyncio
import aiohttp
import pandas as pd
import json
import time
import logging
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import signal
import sys
import os
from concurrent.futures import ThreadPoolExecutor

# å¯¼å…¥æ–‡ä»¶æ£€æµ‹å™¨
sys.path.append(str(Path(__file__).parent.parent))
from implementations.python.file_detector import IncrementalFileDetector

@dataclass
class ProcessingConfig:
    """å¤„ç†é…ç½®"""
    data_dir: str
    output_dir: str
    api_url: str
    max_concurrent: int = 50
    batch_size: int = 200
    timeout: int = 30
    stability_window: int = 30  # æ–‡ä»¶ç¨³å®šæ€§æ£€æµ‹çª—å£
    resume: bool = True  # æ–­ç‚¹ç»­ä¼ 
    save_format: str = "parquet"  # è¾“å‡ºæ ¼å¼: parquet æˆ– json
    log_level: str = "INFO"
    max_workers: int = None  # æœ€å¤§å·¥ä½œè¿›ç¨‹æ•°ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
    
    # æ€§èƒ½æµ‹è¯•ç›¸å…³é…ç½®
    performance_test: bool = False  # æ˜¯å¦å¯ç”¨æ€§èƒ½æµ‹è¯•æ¨¡å¼
    test_files_limit: int = 2  # æ€§èƒ½æµ‹è¯•æ—¶æœ€å¤§æ–‡ä»¶æ•°
    test_samples_per_file: int = 1000  # æ¯ä¸ªæ–‡ä»¶æœ€å¤§æ ·æœ¬æ•°
    enable_monitoring: bool = False  # æ˜¯å¦å¯ç”¨ç³»ç»Ÿç›‘æ§
    monitoring_interval: int = 5  # ç›‘æ§é—´éš”(ç§’)

@dataclass
class ProcessingStats:
    """å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
    total_files: int = 0
    processed_files: int = 0
    skipped_files: int = 0
    total_samples: int = 0
    processed_samples: int = 0
    successful_samples: int = 0
    failed_samples: int = 0
    start_time: float = 0
    current_file: str = ""
    processing_time: float = 0
    
    # æ•°æ®é‡ç»Ÿè®¡
    total_file_bytes: int = 0  # æ€»æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    processed_content_bytes: int = 0  # å·²å¤„ç†çš„å®é™…contentå­—èŠ‚æ•°
    
    # æ€§èƒ½æŒ‡æ ‡
    throughput_sps: float = 0  # samples per second
    throughput_gbps: float = 0  # GB per second (åŸºäºcontent)

class TheStackProcessor:
    """The-Stack-v2æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, config: ProcessingConfig):
        self.config = config
        self.stats = ProcessingStats()
        self.session: Optional[aiohttp.ClientSession] = None
        self.file_detector = IncrementalFileDetector(config.stability_window)
        self.shutdown_event = asyncio.Event()
        self.checkpoint_file = Path(config.output_dir) / "processing_checkpoint.json"
        self.processed_files = set()
        
        # æ€§èƒ½æµ‹è¯•ç›¸å…³
        self.performance_results = []
        self.test_start_time = None
        self.system_monitor = None
        
        # è®¾ç½®å·¥ä½œè¿›ç¨‹æ•°
        if config.max_workers is None:
            # æ ¹æ®CPUæ•°é‡å’Œå†…å­˜æƒ…å†µæ™ºèƒ½è®¾ç½®
            cpu_count = os.cpu_count()
            if config.performance_test:
                # æ€§èƒ½æµ‹è¯•æ—¶å¯ä»¥æ›´æ¿€è¿›
                self.max_workers = min(cpu_count // 2, 16)
            else:
                # ç”Ÿäº§ç¯å¢ƒä¿å®ˆè®¾ç½®ï¼Œé¿å…å†…å­˜é—®é¢˜
                self.max_workers = min(cpu_count // 4, 8)
        else:
            self.max_workers = config.max_workers
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(config.output_dir).mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½æ£€æŸ¥ç‚¹ï¼ˆæ€§èƒ½æµ‹è¯•æ—¶è·³è¿‡ï¼‰
        if config.resume and not config.performance_test:
            self.load_checkpoint()
            
        # å¯åŠ¨ç³»ç»Ÿç›‘æ§
        if config.enable_monitoring:
            self.start_system_monitoring()
            
        # åˆå§‹åŒ–æ—¶æ‰«ææ–‡ä»¶è·å–æ€»æ•°æ®é‡ä¿¡æ¯
        self._initial_scan_completed = False
    
    def start_system_monitoring(self):
        """å¯åŠ¨ç³»ç»Ÿç›‘æ§"""
        try:
            import psutil
            self.system_monitor = {
                'enabled': True,
                'interval': self.config.monitoring_interval,
                'history': []
            }
            self.logger.info(f"âœ… å¯ç”¨ç³»ç»Ÿç›‘æ§ (é—´éš”: {self.config.monitoring_interval}ç§’)")
        except ImportError:
            self.logger.warning("âš ï¸ æ— æ³•å¯ç”¨ç³»ç»Ÿç›‘æ§: ç¼ºå°‘psutilåº“")
            self.system_monitor = None
    
    def record_system_stats(self):
        """è®°å½•ç³»ç»ŸçŠ¶æ€"""
        if not self.system_monitor or not self.system_monitor['enabled']:
            return
        
        try:
            import psutil
            
            stats = {
                'timestamp': time.time(),
                'cpu_percent': psutil.cpu_percent(interval=0.1),
                'memory_percent': psutil.virtual_memory().percent,
                'memory_used_gb': psutil.virtual_memory().used / (1024**3),
                'memory_available_gb': psutil.virtual_memory().available / (1024**3),
                'processed_samples': self.stats.processed_samples,
                'throughput_sps': self.stats.throughput_sps
            }
            
            self.system_monitor['history'].append(stats)
            
            # åªä¿ç•™æœ€è¿‘çš„ç›‘æ§æ•°æ®
            if len(self.system_monitor['history']) > 1000:
                self.system_monitor['history'] = self.system_monitor['history'][-1000:]
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ç³»ç»Ÿç›‘æ§è®°å½•å¤±è´¥: {e}")
    
    def scan_data_directory(self, data_dir: Path):
        """æ‰«ææ•°æ®ç›®å½•ï¼Œè®¡ç®—æ€»æ–‡ä»¶æ•°å’Œæ€»æ•°æ®é‡"""
        if self._initial_scan_completed:
            return
            
        self.logger.info("ğŸ” æ‰«ææ•°æ®ç›®å½•ï¼Œè®¡ç®—æ€»é‡...")
        
        parquet_files = list(data_dir.glob("*.parquet"))
        ready_files = []
        total_content_bytes = 0
        
        for file_path in parquet_files:
            # è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶
            if str(file_path) in self.processed_files:
                continue
                
            # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
            if not self.file_detector.is_file_ready(file_path):
                self.logger.debug(f"â³ æ–‡ä»¶æœªå°±ç»ªï¼Œè·³è¿‡: {file_path.name}")
                continue
                
            ready_files.append(file_path)
            
            # ç›´æ¥ä½¿ç”¨æ–‡ä»¶å¤§å°ï¼Œç®€å•å¿«é€Ÿ
            file_size_bytes = self.get_file_size_bytes(file_path)
            total_content_bytes += file_size_bytes
        
        # æ€§èƒ½æµ‹è¯•æ¨¡å¼ä¸‹é™åˆ¶æ–‡ä»¶æ•°
        if self.config.performance_test:
            ready_files = ready_files[:self.config.test_files_limit]
            # é‡æ–°è®¡ç®—é™åˆ¶åçš„æ€»æ•°æ®é‡
            total_content_bytes = 0
            for file_path in ready_files:
                file_size_bytes = self.get_file_size_bytes(file_path)
                total_content_bytes += file_size_bytes
        
        self.stats.total_files = len(ready_files)
        self.stats.total_file_bytes = total_content_bytes
        self._initial_scan_completed = True
        
        self.logger.info(f"ğŸ“Š æ‰«æå®Œæˆ: {len(ready_files)} ä¸ªå°±ç»ªæ–‡ä»¶, æ€»è®¡ {total_content_bytes / (1024**3):.2f} GB")
    
    def get_file_size_bytes(self, file_path: Path) -> int:
        """è·å–æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
        try:
            return file_path.stat().st_size
        except Exception as e:
            self.logger.warning(f"âš ï¸ è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path.name}: {e}")
            return 0
    
    async def generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        if not self.config.performance_test or not self.test_start_time:
            return
        
        total_time = time.time() - self.test_start_time
        
        # åŸºç¡€æ€§èƒ½æŒ‡æ ‡
        performance_data = {
            "test_configuration": {
                "max_concurrent": self.config.max_concurrent,
                "batch_size": self.config.batch_size,
                "max_workers": self.max_workers,
                "test_files_limit": self.config.test_files_limit,
                "test_samples_per_file": self.config.test_samples_per_file
            },
            "performance_results": {
                "total_processing_time": total_time,
                "total_files_processed": self.stats.processed_files,
                "total_samples_processed": self.stats.processed_samples,
                "successful_samples": self.stats.successful_samples,
                "failed_samples": self.stats.failed_samples,
                "success_rate": self.stats.successful_samples / max(self.stats.processed_samples, 1),
                "throughput_sps": self.stats.processed_samples / max(total_time, 1),
                "throughput_gbps": (self.stats.processed_content_bytes / (1024**3)) / max(total_time, 1),
                "cpu_cores": os.cpu_count(),
                "estimated_daily_capacity_samples": (self.stats.processed_samples / max(total_time, 1)) * 86400,  # 24å°æ—¶
                "estimated_daily_capacity_gb": ((self.stats.processed_content_bytes / (1024**3)) / max(total_time, 1)) * 86400
            }
        }
        
        # ç³»ç»Ÿç›‘æ§æ•°æ®
        if self.system_monitor and self.system_monitor['history']:
            cpu_usage = [s['cpu_percent'] for s in self.system_monitor['history']]
            memory_usage = [s['memory_percent'] for s in self.system_monitor['history']]
            
            performance_data["system_monitoring"] = {
                "avg_cpu_percent": sum(cpu_usage) / len(cpu_usage),
                "max_cpu_percent": max(cpu_usage),
                "avg_memory_percent": sum(memory_usage) / len(memory_usage),
                "max_memory_percent": max(memory_usage),
                "monitoring_samples": len(self.system_monitor['history'])
            }
        
        # ä¼°ç®—ä¸åŒæ•°æ®é‡çš„å¤„ç†æ—¶é—´
        if self.stats.processed_samples > 0:
            samples_per_sec = self.stats.processed_samples / total_time
            
            # ä¼°ç®—å¤„ç†å¤§è§„æ¨¡æ•°æ®çš„æ—¶é—´
            estimates = {
                "1M_samples": {"time_hours": 1_000_000 / samples_per_sec / 3600},
                "10M_samples": {"time_hours": 10_000_000 / samples_per_sec / 3600},
                "100M_samples": {"time_hours": 100_000_000 / samples_per_sec / 3600}
            }
            
            performance_data["scale_estimates"] = estimates
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = Path(self.config.output_dir) / "performance_test_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(performance_data, f, indent=2, ensure_ascii=False)
        
        # è¾“å‡ºæ‘˜è¦
        self.logger.info(f"\n" + "="*60)
        self.logger.info(f"ğŸ† æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
        self.logger.info(f"="*60)
        self.logger.info(f"æµ‹è¯•é…ç½®: å¹¶å‘={self.config.max_concurrent}, æ‰¹æ¬¡={self.config.batch_size}")
        self.logger.info(f"å¤„ç†æ—¶é—´: {total_time:.1f} ç§’")
        self.logger.info(f"å¤„ç†æ ·æœ¬: {self.stats.processed_samples:,}")
        self.logger.info(f"å¤„ç†æ•°æ®: {self.stats.processed_content_bytes / (1024**3):.2f} GB")
        self.logger.info(f"æˆåŠŸç‡: {performance_data['performance_results']['success_rate']:.1%}")
        self.logger.info(f"ååé‡: {performance_data['performance_results']['throughput_sps']:.1f} samples/sec")
        self.logger.info(f"ğŸ¯ å†…å®¹å¤„ç†é€Ÿåº¦: {performance_data['performance_results']['throughput_gbps']:.3f} GB/s")
        self.logger.info(f"é¢„ä¼°æ—¥å¤„ç†é‡: {performance_data['performance_results']['estimated_daily_capacity_samples']:,.0f} æ ·æœ¬ | {performance_data['performance_results']['estimated_daily_capacity_gb']:.1f} GB")
        
        if "system_monitoring" in performance_data:
            mon = performance_data["system_monitoring"]
            self.logger.info(f"å¹³å‡CPUä½¿ç”¨: {mon['avg_cpu_percent']:.1f}%")
            self.logger.info(f"å¹³å‡å†…å­˜ä½¿ç”¨: {mon['avg_memory_percent']:.1f}%")
        
        if "scale_estimates" in performance_data:
            est = performance_data["scale_estimates"]
            self.logger.info(f"\nğŸ“Š å¤§è§„æ¨¡å¤„ç†é¢„ä¼°:")
            self.logger.info(f"  100ä¸‡æ ·æœ¬: {est['1M_samples']['time_hours']:.1f} å°æ—¶")
            self.logger.info(f"  1000ä¸‡æ ·æœ¬: {est['10M_samples']['time_hours']:.1f} å°æ—¶")
            self.logger.info(f"  1äº¿æ ·æœ¬: {est['100M_samples']['time_hours']:.1f} å°æ—¶")
        
        self.logger.info(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šä¿å­˜åˆ°: {report_file}")
        self.logger.info(f"="*60)
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_level = getattr(logging, self.config.log_level.upper())
        
        # é…ç½®æ—¥å¿—æ ¼å¼
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        
        # æ–‡ä»¶å¤„ç†å™¨
        log_file = Path(self.config.output_dir) / "processing.log"
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setFormatter(formatter)
        
        # é…ç½®logger
        self.logger = logging.getLogger('TheStackProcessor')
        self.logger.setLevel(log_level)
        self.logger.addHandler(console_handler)
        self.logger.addHandler(file_handler)
    
    def load_checkpoint(self):
        """åŠ è½½å¤„ç†æ£€æŸ¥ç‚¹"""
        if self.checkpoint_file.exists():
            try:
                with open(self.checkpoint_file, 'r', encoding='utf-8') as f:
                    checkpoint = json.load(f)
                    self.processed_files = set(checkpoint.get('processed_files', []))
                    self.logger.info(f"ğŸ“‚ åŠ è½½æ£€æŸ¥ç‚¹: å·²å¤„ç† {len(self.processed_files)} ä¸ªæ–‡ä»¶")
            except Exception as e:
                self.logger.warning(f"âš ï¸ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def save_checkpoint(self):
        """ä¿å­˜å¤„ç†æ£€æŸ¥ç‚¹"""
        try:
            checkpoint = {
                'processed_files': list(self.processed_files),
                'last_update': time.time(),
                'stats': asdict(self.stats)
            }
            with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(checkpoint, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        # é…ç½®HTTPä¼šè¯
        connector = aiohttp.TCPConnector(
            limit=self.config.max_concurrent * 2,
            limit_per_host=self.config.max_concurrent,
            ttl_dns_cache=300,
            use_dns_cache=True,
        )
        timeout = aiohttp.ClientTimeout(total=self.config.timeout)
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout
        )
        
        # å¥åº·æ£€æŸ¥
        await self.health_check()
        
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()
    
    async def health_check(self):
        """APIå¥åº·æ£€æŸ¥"""
        try:
            async with self.session.get(f"{self.config.api_url}/health") as response:
                if response.status == 200:
                    health_info = await response.json()
                    self.logger.info(f"âœ… APIæœåŠ¡å¥åº·: {health_info.get('status', 'unknown')}")
                else:
                    self.logger.warning(f"âš ï¸ APIå¥åº·æ£€æŸ¥å¼‚å¸¸: HTTP {response.status}")
        except Exception as e:
            self.logger.error(f"âŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡: {e}")
            raise
    
    def preprocess_content(self, content: str) -> Optional[str]:
        """é¢„å¤„ç†ä»£ç å†…å®¹"""
        if not content or not isinstance(content, str):
            return None
        
        # åŸºæœ¬æ¸…ç†
        content = content.strip()
        
        # é•¿åº¦æ£€æŸ¥
        if len(content) == 0:
            return None
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šé¢„å¤„ç†é€»è¾‘
        return content
    
    async def predict_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """æ‰¹é‡é¢„æµ‹"""
        try:
            async with self.session.post(
                f"{self.config.api_url}/predict",
                json=texts,
                params={"k": 2, "threshold": 0.0}
            ) as response:
                if response.status == 200:
                    results = await response.json()
                    
                    # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                    formatted_results = []
                    for result in results:
                        if isinstance(result, dict) and "labels" in result:
                            # æ–°æ ¼å¼: {"labels": [...], "scores": [...]}
                            formatted_results.append({
                                "labels": result["labels"],
                                "scores": result["scores"],
                                "prediction": result["labels"][0] if result["labels"] else "__label__0",
                                "confidence": result["scores"][0] if result["scores"] else 0.0
                            })
                        elif isinstance(result, (list, tuple)) and len(result) == 2:
                            # æ—§æ ¼å¼: [labels, scores]
                            labels, scores = result
                            formatted_results.append({
                                "labels": labels,
                                "scores": scores,
                                "prediction": labels[0] if labels else "__label__0",
                                "confidence": scores[0] if scores else 0.0
                            })
                        else:
                            # å¼‚å¸¸æ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤å€¼
                            formatted_results.append({
                                "labels": ["__label__0"],
                                "scores": [0.0],
                                "prediction": "__label__0",
                                "confidence": 0.0
                            })
                    
                    return formatted_results
                else:
                    error_text = await response.text()
                    self.logger.error(f"APIé”™è¯¯: HTTP {response.status} - {error_text}")
                    # è¿”å›é»˜è®¤ç»“æœ
                    return [self._get_default_prediction() for _ in texts]
                    
        except Exception as e:
            self.logger.error(f"é¢„æµ‹è¯·æ±‚å¼‚å¸¸: {e}")
            return [self._get_default_prediction() for _ in texts]
    
    def _get_default_prediction(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é¢„æµ‹ç»“æœ"""
        return {
            "labels": ["__label__0"],
            "scores": [0.0],
            "prediction": "__label__0",
            "confidence": 0.0
        }
    
    def postprocess_results(self, original_data: List[Dict], predictions: List[Dict]) -> List[Dict]:
        """åå¤„ç†ç»“æœï¼Œç”Ÿæˆæœ€ç»ˆè¾“å‡º"""
        results = []
        
        for original, prediction in zip(original_data, predictions):
            # éªŒè¯é¢„æµ‹ç»“æœçš„æœ‰æ•ˆæ€§
            is_valid, error_reason = self.validate_prediction(prediction)
            
            # æ„å»ºè¾“å‡ºè®°å½•
            result = {
                # ä¿ç•™å…³é”®åŸå§‹å­—æ®µ
                "blob_id": original.get("blob_id"),
                "path": original.get("path"),
                "repo_name": original.get("repo_name"),
                "language": original.get("language"),
                "size": original.get("size"),
                "ext": original.get("ext"),
                
                # æ·»åŠ è´¨é‡åˆ†ç±»ç»“æœ
                "quality_labels": prediction["labels"],
                "quality_scores": prediction["scores"],
                "quality_prediction": prediction["prediction"],
                "quality_confidence": prediction["confidence"],
                
                # æ•°æ®æœ‰æ•ˆæ€§æ ‡è®°
                "prediction_valid": is_valid,
                "prediction_error": error_reason if not is_valid else None,
                
                # å¤„ç†å…ƒä¿¡æ¯
                "content_length": len(str(original.get("content", ""))),
                "processed_at": pd.Timestamp.now().isoformat()
            }
            
            results.append(result)
        
        return results
    
    def validate_prediction(self, prediction: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
        """éªŒè¯é¢„æµ‹ç»“æœçš„æœ‰æ•ˆæ€§"""
        try:
            labels = prediction.get("labels", [])
            scores = prediction.get("scores", [])
            
            # åŸºæœ¬æ ¼å¼æ£€æŸ¥
            if not isinstance(labels, list) or not isinstance(scores, list):
                return False, "invalid_format_not_list"
            
            if len(labels) != len(scores):
                return False, "length_mismatch"
            
            if len(labels) == 0:
                return False, "empty_prediction"
            
            # æ£€æŸ¥æ ‡ç­¾æ ¼å¼
            valid_labels = {"__label__0", "__label__1"}
            for label in labels:
                if label not in valid_labels:
                    return False, f"invalid_label_{label}"
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„æœŸçš„æ ‡ç­¾ç»„åˆ
            label_set = set(labels)
            if len(label_set) > 2:
                return False, f"too_many_unique_labels_{len(label_set)}"
            
            # æ£€æŸ¥åˆ†æ•°æ˜¯å¦æŒ‰é™åºæ’åˆ—
            if scores != sorted(scores, reverse=True):
                return False, "scores_not_descending"
            
            return True, None
            
        except Exception as e:
            return False, f"validation_exception_{str(e)}"
    
    async def process_file(self, file_path: Path, semaphore: asyncio.Semaphore) -> bool:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        async with semaphore:
            start_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
            if self.config.resume and str(file_path) in self.processed_files:
                self.logger.info(f"â­ï¸ è·³è¿‡å·²å¤„ç†æ–‡ä»¶: {file_path.name}")
                self.stats.skipped_files += 1
                return True
            
            self.stats.current_file = file_path.name
            self.logger.info(f"ğŸ“„ å¼€å§‹å¤„ç†: {file_path.name}")
            
            try:
                # ä½¿ç”¨æµå¼åˆ†æ‰¹è¯»å–ï¼Œé¿å…å¤§æ–‡ä»¶å†…å­˜çˆ†ç‚¸
                import pyarrow.parquet as pq
                
                parquet_file = pq.ParquetFile(file_path)
                total_rows = parquet_file.metadata.num_rows
                
                if total_rows == 0:
                    self.logger.warning(f"âš ï¸ ç©ºæ–‡ä»¶: {file_path.name}")
                    self.processed_files.add(str(file_path))
                    return True
                
                # æ£€æŸ¥å¿…éœ€åˆ—
                schema = parquet_file.schema_arrow
                if 'content' not in schema.names:
                    self.logger.error(f"âŒ ç¼ºå°‘contentåˆ—: {file_path.name}")
                    return False
                
                # è®¡ç®—åŠ¨æ€ç¼“å­˜å¤§å°ï¼šåŸºäºå½“å‰å¹¶å‘é…ç½®
                # cache_size = å¹¶å‘æ•° * æ‰¹æ¬¡å¤§å° * ç¼“å†²å€æ•°
                cache_size = self.config.max_concurrent * self.config.batch_size * 3
                
                # æ€§èƒ½æµ‹è¯•æ¨¡å¼ä¸‹é™åˆ¶æ ·æœ¬æ•°
                max_samples = None
                if self.config.performance_test:
                    max_samples = self.config.test_samples_per_file
                    self.logger.info(f"ğŸ§ª æ€§èƒ½æµ‹è¯•æ¨¡å¼: é™åˆ¶æ ·æœ¬æ•° {max_samples}")
                
                self.logger.info(f"ğŸ“Š {file_path.name}: æ€»è¡Œæ•° {total_rows:,}, ç¼“å­˜å¤§å° {cache_size:,}")
                
                # æµå¼å¤„ç†ï¼šåˆ†æ‰¹è¯»å–å’Œå¤„ç†
                all_results = []
                file_content_bytes = 0
                processed_count = 0
                
                for batch in parquet_file.iter_batches(batch_size=cache_size):
                    # è½¬æ¢ä¸ºpandas DataFrameè¿›è¡Œå¤„ç†
                    df_chunk = batch.to_pandas()
                    
                    # é¢„å¤„ç†è¿™ä¸ªchunkçš„æ•°æ®
                    chunk_data = []
                    chunk_texts = []
                    
                    for idx, row in df_chunk.iterrows():
                        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ ·æœ¬é™åˆ¶
                        if max_samples and processed_count >= max_samples:
                            break
                            
                        content = self.preprocess_content(row.get('content', ''))
                        if content:
                            chunk_data.append(row.to_dict())
                            chunk_texts.append(content)
                            file_content_bytes += len(content.encode('utf-8'))
                            processed_count += 1
                    
                    if not chunk_texts:
                        continue
                    
                    # åˆ†æ‰¹å¤„ç†è¿™ä¸ªchunkçš„æ•°æ®
                    chunk_results = []
                    for i in range(0, len(chunk_texts), self.config.batch_size):
                        batch_texts = chunk_texts[i:i + self.config.batch_size]
                        batch_data = chunk_data[i:i + self.config.batch_size]
                        
                        if not batch_texts:
                            continue
                        
                        # å¼‚æ­¥æ¨ç†ï¼ˆä¿¡å·é‡æ§åˆ¶åœ¨å¤–å±‚ï¼‰
                        async with semaphore:
                            predictions = await self.predict_batch(batch_texts)
                        
                        # åå¤„ç†
                        batch_results = self.postprocess_results(batch_data, predictions)
                        chunk_results.extend(batch_results)
                        
                        # æ›´æ–°ç»Ÿè®¡
                        valid_count = sum(1 for r in batch_results if r.get('prediction_valid', False))
                        self.stats.successful_samples += valid_count
                        self.stats.failed_samples += len(batch_results) - valid_count
                    
                    all_results.extend(chunk_results)
                    
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ ·æœ¬é™åˆ¶
                    if max_samples and processed_count >= max_samples:
                        break
                
                if not all_results:
                    self.logger.warning(f"âš ï¸ æ— æœ‰æ•ˆå†…å®¹: {file_path.name}")
                    self.processed_files.add(str(file_path))
                    return True
                
                self.logger.info(f"ğŸ“Š {file_path.name}: æµå¼å¤„ç†å®Œæˆ {processed_count} ä¸ªæ ·æœ¬, {file_content_bytes / (1024**2):.1f} MB å†…å®¹")
                self.stats.total_samples += processed_count
                
                # ä¿å­˜ç»“æœ
                success = await self.save_file_results(file_path, all_results)
                
                if success:
                    # æ›´æ–°ç»Ÿè®¡å’Œæ£€æŸ¥ç‚¹
                    self.processed_files.add(str(file_path))
                    self.stats.processed_files += 1
                    self.stats.processed_content_bytes += file_content_bytes
                    
                    processing_time = time.time() - start_time
                    self.stats.processing_time += processing_time
                    
                    throughput = processed_count / processing_time
                    # è®¡ç®—GB/så¤„ç†é€Ÿåº¦
                    content_gb = file_content_bytes / (1024**3)
                    throughput_gbps = content_gb / processing_time
                    self.logger.info(f"âœ… å®Œæˆ: {file_path.name} "
                                   f"({processed_count} æ ·æœ¬, {throughput:.1f} samples/sec, "
                                   f"{throughput_gbps:.3f} GB/s)")
                    
                    # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
                    if self.stats.processed_files % 5 == 0:
                        self.save_checkpoint()
                    
                    return True
                else:
                    return False
                    
            except Exception as e:
                self.logger.error(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {file_path.name} - {e}")
                return False
    
    async def save_file_results(self, original_file: Path, results: List[Dict]) -> bool:
        """ä¿å­˜å•ä¸ªæ–‡ä»¶çš„å¤„ç†ç»“æœ"""
        try:
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            output_name = f"processed_{original_file.stem}.{self.config.save_format}"
            output_path = Path(self.config.output_dir) / output_name
            
            if self.config.save_format == "parquet":
                df = pd.DataFrame(results)
                df.to_parquet(output_path, index=False)
            else:  # json
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, indent=2, ensure_ascii=False)
            
            self.logger.debug(f"ğŸ’¾ ä¿å­˜ç»“æœ: {output_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return False
    
    def update_progress_display(self):
        """æ›´æ–°è¿›åº¦æ˜¾ç¤º"""
        elapsed_time = time.time() - self.stats.start_time
        
        # æ–‡ä»¶è¿›åº¦
        if self.stats.total_files > 0:
            file_progress_pct = (self.stats.processed_files / self.stats.total_files) * 100
            file_progress_str = f"{self.stats.processed_files}/{self.stats.total_files} ({file_progress_pct:.1f}%)"
        else:
            file_progress_str = f"{self.stats.processed_files}"
        
        # æ•°æ®é‡è¿›åº¦
        processed_content_gb = self.stats.processed_content_bytes / (1024**3)
        if self.stats.total_file_bytes > 0:
            total_file_gb = self.stats.total_file_bytes / (1024**3)
            # è¿™é‡Œä¸åšç™¾åˆ†æ¯”ï¼Œå› ä¸ºcontentå­—èŠ‚æ•°å’Œæ–‡ä»¶å¤§å°ä¸èƒ½ç›´æ¥æ¯”è¾ƒ
            data_progress_str = f"{processed_content_gb:.2f}GBå†…å®¹ / {total_file_gb:.2f}GBæ–‡ä»¶"
        else:
            data_progress_str = f"{processed_content_gb:.2f}GBå†…å®¹"
        
        # æ€§èƒ½æŒ‡æ ‡
        if elapsed_time > 0:
            current_throughput = self.stats.processed_samples / elapsed_time
            current_throughput_gbps = processed_content_gb / elapsed_time
            self.stats.throughput_sps = current_throughput
            self.stats.throughput_gbps = current_throughput_gbps
        else:
            current_throughput = 0
            current_throughput_gbps = 0
        
        print(f"\rğŸ“Š è¿›åº¦: æ–‡ä»¶ {file_progress_str} | "
              f"æ•°æ® {data_progress_str} | "
              f"{current_throughput:.1f} samples/sec | "
              f"{current_throughput_gbps:.3f} GB/s | "
              f"ç”¨æ—¶: {elapsed_time:.0f}s", end="", flush=True)
    
    async def run(self):
        """è¿è¡Œä¸»å¤„ç†æµç¨‹"""
        mode = "æ€§èƒ½æµ‹è¯•" if self.config.performance_test else "ç”Ÿäº§å¤„ç†"
        self.logger.info(f"ğŸš€ å¼€å§‹å¤„ç†The-Stack-v2æ•°æ® ({mode})")
        self.logger.info(f"æ•°æ®ç›®å½•: {self.config.data_dir}")
        self.logger.info(f"è¾“å‡ºç›®å½•: {self.config.output_dir}")
        self.logger.info(f"APIåœ°å€: {self.config.api_url}")
        self.logger.info(f"APIå¹¶å‘æ•°: {self.config.max_concurrent}")
        self.logger.info(f"æ‰¹æ¬¡å¤§å°: {self.config.batch_size}")
        self.logger.info(f"CPUæ ¸å¿ƒæ•°: {os.cpu_count()}")
        self.logger.info(f"å·¥ä½œè¿›ç¨‹æ•°: {self.max_workers}")
        
        if self.config.performance_test:
            self.logger.info(f"ğŸ§ª æ€§èƒ½æµ‹è¯•é…ç½®:")
            self.logger.info(f"  æœ€å¤§æ–‡ä»¶æ•°: {self.config.test_files_limit}")
            self.logger.info(f"  æ¯æ–‡ä»¶æ ·æœ¬æ•°: {self.config.test_samples_per_file}")
            self.test_start_time = time.time()
        
        data_dir = Path(self.config.data_dir)
        if not data_dir.exists():
            self.logger.error(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
            return
        
        # åˆå§‹æ‰«ææ•°æ®ç›®å½•
        self.scan_data_directory(data_dir)
        
        self.stats.start_time = time.time()
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        def signal_handler(signum, frame):
            self.logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡ä¼˜é›…å…³é—­...")
            self.shutdown_event.set()
        
        signal.signal(signal.SIGTERM, signal_handler)
        signal.signal(signal.SIGINT, signal_handler)
        
        try:
            # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘
            semaphore = asyncio.Semaphore(self.config.max_concurrent)
            
            # æ‰«ææ‰€æœ‰å¯å¤„ç†çš„æ–‡ä»¶
            all_parquet_files = list(data_dir.glob("*.parquet"))
            self.logger.info(f"ğŸ” å‘ç° {len(all_parquet_files)} ä¸ªparquetæ–‡ä»¶")
            
            all_ready_files = []
            for file_path in all_parquet_files:
                is_ready = self.file_detector.is_file_ready(file_path)
                if is_ready:
                    all_ready_files.append(file_path)
                    self.logger.debug(f"âœ… å°±ç»ª: {file_path.name}")
                else:
                    self.logger.info(f"â³ æœªå°±ç»ª: {file_path.name}")
            
            self.logger.info(f"ğŸ“Š å…¶ä¸­ {len(all_ready_files)} ä¸ªæ–‡ä»¶å°±ç»ªå¯å¤„ç†")
            
            # è¿‡æ»¤å·²å¤„ç†çš„æ–‡ä»¶
            if self.config.resume and not self.config.performance_test:
                files_to_process = [f for f in all_ready_files if str(f) not in self.processed_files]
                self.logger.info(f"ğŸ“‹ è¿‡æ»¤åå‰©ä½™ {len(files_to_process)} ä¸ªæœªå¤„ç†æ–‡ä»¶")
            else:
                files_to_process = all_ready_files
            
            # æ€§èƒ½æµ‹è¯•æ¨¡å¼ä¸‹é™åˆ¶æ–‡ä»¶æ•°é‡
            if self.config.performance_test:
                files_to_process = files_to_process[:self.config.test_files_limit]
                self.logger.info(f"ğŸ§ª æ€§èƒ½æµ‹è¯•æ¨¡å¼: é™åˆ¶å¤„ç† {len(files_to_process)} ä¸ªæ–‡ä»¶")
            
            if not files_to_process:
                if self.config.performance_test:
                    self.logger.error("âŒ æ€§èƒ½æµ‹è¯•: æ²¡æœ‰å¯å¤„ç†çš„æ–‡ä»¶")
                    return
                else:
                    self.logger.info("â³ æš‚æ— å¯å¤„ç†æ–‡ä»¶ï¼Œè¿›å…¥ç›‘æ§æ¨¡å¼...")
            else:
                self.logger.info(f"ğŸ“ æ‰¾åˆ° {len(files_to_process)} ä¸ªæ–‡ä»¶å¾…å¤„ç†")
                
                # é€ä¸ªå¤„ç†æ–‡ä»¶ï¼ˆæ–‡ä»¶çº§ä¸²è¡Œï¼‰
                files_processed = 0
                for file_path in files_to_process:
                    if self.shutdown_event.is_set():
                        break
                    
                    # æ›´æ–°è¿›åº¦æ˜¾ç¤º
                    self.update_progress_display()
                    
                    # è®°å½•ç³»ç»ŸçŠ¶æ€
                    self.record_system_stats()
                    
                    # å¤„ç†æ–‡ä»¶
                    success = await self.process_file(file_path, semaphore)
                    
                    if success:
                        files_processed += 1
                        self.logger.info(f"âœ… å®Œæˆæ–‡ä»¶ {files_processed}/{len(files_to_process)}: {file_path.name}")
                    else:
                        self.logger.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ï¼Œè·³è¿‡: {file_path.name}")
                
                # æ¸…ç†æ–‡ä»¶çŠ¶æ€ç¼“å­˜
                self.file_detector.cleanup_states(data_dir)
                
                # æ€§èƒ½æµ‹è¯•æ¨¡å¼ï¼šå¤„ç†å®Œå°±é€€å‡º
                if self.config.performance_test:
                    self.logger.info(f"ğŸ‰ æ€§èƒ½æµ‹è¯•å®Œæˆï¼å¤„ç†äº† {files_processed} ä¸ªæ–‡ä»¶")
                    await self.generate_performance_report()
                    return
                
                self.logger.info("âœ… å½“å‰æ‰¹æ¬¡å¤„ç†å®Œæˆ")
            
            # ç”Ÿäº§æ¨¡å¼ï¼šç›‘æ§æ–°æ–‡ä»¶ï¼ˆä»…åœ¨éæ€§èƒ½æµ‹è¯•æ¨¡å¼ï¼‰
            if not self.config.performance_test:
                self.logger.info("ğŸ”„ è¿›å…¥å¢é‡ç›‘æ§æ¨¡å¼ï¼Œç­‰å¾…æ–°æ–‡ä»¶...")
                while not self.shutdown_event.is_set():
                    await asyncio.sleep(60)  # ç­‰å¾…1åˆ†é’Ÿ
                    
                    # é‡æ–°æ‰«ææ–°æ–‡ä»¶
                    current_ready_files = self.file_detector.scan_ready_files(data_dir)
                    new_files = [f for f in current_ready_files if str(f) not in self.processed_files]
                    
                    if new_files:
                        self.logger.info(f"ğŸ“ å‘ç° {len(new_files)} ä¸ªæ–°æ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...")
                        for file_path in new_files:
                            if self.shutdown_event.is_set():
                                break
                            
                            success = await self.process_file(file_path, semaphore)
                            if success:
                                self.logger.info(f"âœ… æ–°æ–‡ä»¶å¤„ç†å®Œæˆ: {file_path.name}")
                            else:
                                self.logger.error(f"âŒ æ–°æ–‡ä»¶å¤„ç†å¤±è´¥: {file_path.name}")
                    else:
                        self.logger.debug("â³ æš‚æ— æ–°æ–‡ä»¶...")
        
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        
        finally:
            # æœ€ç»ˆä¿å­˜æ£€æŸ¥ç‚¹
            self.save_checkpoint()
            
            # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
            total_time = time.time() - self.stats.start_time
            print(f"\n\nğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
            print(f"  æ€»å¤„ç†æ—¶é—´: {total_time:.1f} ç§’")
            print(f"  å¤„ç†æ–‡ä»¶æ•°: {self.stats.processed_files}")
            print(f"  è·³è¿‡æ–‡ä»¶æ•°: {self.stats.skipped_files}")
            print(f"  å¤„ç†æ ·æœ¬æ•°: {self.stats.processed_samples}")
            print(f"  æˆåŠŸæ ·æœ¬æ•°: {self.stats.successful_samples}")
            print(f"  å¤±è´¥æ ·æœ¬æ•°: {self.stats.failed_samples}")
            if self.stats.processed_samples > 0:
                success_rate = (self.stats.successful_samples / self.stats.processed_samples) * 100
                print(f"  æˆåŠŸç‡: {success_rate:.1f}%")
            if total_time > 0:
                overall_throughput = self.stats.processed_samples / total_time
                print(f"  å¹³å‡ååé‡: {overall_throughput:.1f} samples/sec")

async def main():
    parser = argparse.ArgumentParser(
        description='The-Stack-v2 å¤§è§„æ¨¡ä»£ç è´¨é‡åˆ†ç±»å¤„ç†å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºæœ¬ä½¿ç”¨
  python3 the_stack_processor.py \\
    --data-dir /path/to/the-stack-v2 \\
    --output-dir /path/to/results \\
    --api-url http://fasttext-api:8000

  # é«˜æ€§èƒ½é…ç½®
  python3 the_stack_processor.py \\
    --data-dir /path/to/the-stack-v2 \\
    --output-dir /path/to/results \\
    --api-url http://fasttext-api:8000 \\
    --max-concurrent 80 \\
    --batch-size 200

  # ä»æ–­ç‚¹ç»§ç»­å¤„ç†
  python3 the_stack_processor.py \\
    --data-dir /path/to/the-stack-v2 \\
    --output-dir /path/to/results \\
    --api-url http://fasttext-api:8000 \\
    --resume
        """
    )
    
    parser.add_argument('--data-dir', required=True,
                        help='The-Stack-v2æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--output-dir', required=True,
                        help='å¤„ç†ç»“æœè¾“å‡ºç›®å½•')
    parser.add_argument('--api-url', required=True,
                        help='FastText APIæœåŠ¡åœ°å€')
    parser.add_argument('--max-concurrent', type=int, default=50,
                        help='æœ€å¤§å¹¶å‘è¯·æ±‚æ•° (é»˜è®¤: 50)')
    parser.add_argument('--batch-size', type=int, default=200,
                        help='æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 200)')
    parser.add_argument('--timeout', type=int, default=30,
                        help='è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) (é»˜è®¤: 30)')
    parser.add_argument('--stability-window', type=int, default=30,
                        help='æ–‡ä»¶ç¨³å®šæ€§æ£€æµ‹çª—å£(ç§’) (é»˜è®¤: 30)')
    parser.add_argument('--resume', action='store_true',
                        help='ä»æ–­ç‚¹ç»§ç»­å¤„ç†')
    parser.add_argument('--save-format', choices=['parquet', 'json'], default='parquet',
                        help='è¾“å‡ºæ–‡ä»¶æ ¼å¼ (é»˜è®¤: parquet)')
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], default='INFO',
                        help='æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)')
    parser.add_argument('--max-workers', type=int,
                        help='æœ€å¤§å·¥ä½œè¿›ç¨‹æ•° (é»˜è®¤: è‡ªåŠ¨æ£€æµ‹)')
    
    # æ€§èƒ½æµ‹è¯•ç›¸å…³å‚æ•°
    parser.add_argument('--performance-test', action='store_true',
                        help='å¯ç”¨æ€§èƒ½æµ‹è¯•æ¨¡å¼')
    parser.add_argument('--test-files-limit', type=int, default=2,
                        help='æ€§èƒ½æµ‹è¯•æ—¶æœ€å¤§æ–‡ä»¶æ•° (é»˜è®¤: 2)')
    parser.add_argument('--test-samples-per-file', type=int, default=1000,
                        help='æ€§èƒ½æµ‹è¯•æ—¶æ¯æ–‡ä»¶æœ€å¤§æ ·æœ¬æ•° (é»˜è®¤: 1000)')
    parser.add_argument('--enable-monitoring', action='store_true',
                        help='å¯ç”¨ç³»ç»Ÿèµ„æºç›‘æ§')
    parser.add_argument('--monitoring-interval', type=int, default=5,
                        help='ç³»ç»Ÿç›‘æ§é—´éš”(ç§’) (é»˜è®¤: 5)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºé…ç½®
    config = ProcessingConfig(
        data_dir=args.data_dir,
        output_dir=args.output_dir,
        api_url=args.api_url,
        max_concurrent=args.max_concurrent,
        batch_size=args.batch_size,
        timeout=args.timeout,
        stability_window=args.stability_window,
        resume=args.resume,
        save_format=args.save_format,
        log_level=args.log_level,
        max_workers=args.max_workers,
        performance_test=args.performance_test,
        test_files_limit=args.test_files_limit,
        test_samples_per_file=args.test_samples_per_file,
        enable_monitoring=args.enable_monitoring,
        monitoring_interval=args.monitoring_interval
    )
    
    # è¿è¡Œå¤„ç†å™¨
    async with TheStackProcessor(config) as processor:
        await processor.run()

if __name__ == "__main__":
    asyncio.run(main())
